{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cluster_ids = pd.read_csv(\"../../data/rowClustered.csv\")\n",
    "coordinates = pd.read_csv(\"../../data/t-SNE_projected.csv\")\n",
    "row_data = pd.read_csv(\"../../data/big_data/the-reddit-climate-change-dataset-comments.csv\", nrows=500_000)\n",
    "with open(\"../../data/names.json\") as json_file:\n",
    "    cluster_names = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamps\n",
    "def generate_timestamps(year, count):\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31, 23, 59, 59)\n",
    "    return [start_date + (end_date - start_date) * random.random() for _ in range(count)]\n",
    "\n",
    "# Distribution of comments per year\n",
    "distribution = {\n",
    "    2011: 5000,\n",
    "    2012: 10000,\n",
    "    2013: 14500,\n",
    "    2014: 17500,\n",
    "    2015: 21300,\n",
    "    2016: 36100,\n",
    "    2017: 51200,\n",
    "    2018: 71000,\n",
    "    2019: 61000,\n",
    "    2020: 49300,\n",
    "    2021: 62000,\n",
    "    2022: 101100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamps for each year\n",
    "timestamps = []\n",
    "for year, count in distribution.items():\n",
    "    timestamps.extend(generate_timestamps(year, count))\n",
    "\n",
    "# Shuffle timestamps to ensure randomness\n",
    "random.shuffle(timestamps)\n",
    "\n",
    "# Convert timestamps to Unix time\n",
    "timestamps_unix = [int(ts.timestamp()) for ts in timestamps]\n",
    "\n",
    "# Assign timestamps to the dataframe\n",
    "row_data[\"created_utc\"] = timestamps_unix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "result = pd.concat([cluster_ids, coordinates], axis=1).drop(columns=[\"Unnamed: 0\"])\n",
    "result[\"body\"] = row_data[\"body\"]\n",
    "result['cluster_id'] = result['cluster_id'].apply(lambda x: cluster_names[str(x)])\n",
    "result[\"created_utc\"] = pd.to_datetime(row_data[\"created_utc\"], unit=\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"../../data/result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
